{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be79ff7d",
   "metadata": {},
   "source": [
    "# 1. Preprocessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b0e9d2",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "973c713b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import bisect\n",
    "import calendar\n",
    "import gc\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\");\n",
    "\n",
    "RAND = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6468de",
   "metadata": {},
   "source": [
    "# Описание данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7425ba",
   "metadata": {},
   "source": [
    "Материалы (1 415 MB)\n",
    "\n",
    "public_train.pqt\n",
    "3 MB\t\n",
    "\n",
    "competition_data_final_pqt.zip\n",
    "1 405 MB\t\n",
    "\n",
    "Context_Baseline_Public.ipynb\n",
    "1 MB\t\n",
    "\n",
    "submit_2.pqt\n",
    "в этом файле id, по которым нужно предсказать пол и возраст\n",
    "2 MB\t\n",
    "\n",
    "sample_submission.csv\n",
    "По возрасту классы: Класс 1 —19-25, Класс 2 —26-35, Класс 3 —36-45, Класс 4 —46-55, Класс 5 —56-65, Класс 6— 66+ \n",
    "4 MB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93863e0e",
   "metadata": {},
   "source": [
    "**Описания полей**\n",
    "\n",
    "- Описание колонок файла с данными:\n",
    "\n",
    "- 'region_name' – Регион\n",
    "\n",
    "- 'city_name' – Населенный пункт\n",
    "\n",
    "- 'cpe_manufacturer_name' – Производитель устройства\n",
    "\n",
    "- 'cpe_model_name' – Модель устройства\n",
    "\n",
    "- 'url_host' – Домен, с которого пришел рекламный запрос\n",
    "\n",
    "- 'cpe_type_cd' – Тип устройства (смартфон или что-то другое)\n",
    "\n",
    "- 'Cpe_model_os_type' – Операционка на устройстве\n",
    "\n",
    "- 'price' – Оценка цены устройства\n",
    "\n",
    "- 'date' – Дата\n",
    "\n",
    "- 'part_of_day' – Время дня (утро, вечер, итд)\n",
    "\n",
    "- 'request_cnt' – Число запросов одного пользователя за время дня (поле part_of_day)\n",
    "\n",
    "- 'user_id' – ID пользователя\n",
    "\n",
    "**Описание колонок файла с таргетами:**\n",
    "\n",
    "- 'age' – Возраст пользователя\n",
    "\n",
    "- 'Is_male' – Признак пользователя : мужчина (1-Да, 0-Нет)\n",
    "\n",
    "- 'user_id' – ID пользователя"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a7db1e",
   "metadata": {},
   "source": [
    "---\n",
    "# Расположение папок с данными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59d00dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_DATA_PATH = \"../data\"\n",
    "DATA_FILE = 'competition_data_final_pqt'\n",
    "\n",
    "# целевые переменные\n",
    "TARGET_FILE = 'public_train.pqt'\n",
    "\n",
    "# id, по которым нужно предсказать пол и возраст\n",
    "SUBMIT_FILE = 'submit_2.pqt'\n",
    "\n",
    "# папка, куда будут сохраняться предобработанные данные\n",
    "PREP_DATA = 'preprocessed_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8bd4df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_DATA_PATH_mts = \"../data/ml_cup_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023ff702",
   "metadata": {},
   "source": [
    "---\n",
    "### Пример, как должен выглядеть ответ.\n",
    "\n",
    "Baseline (id, возраст и пол(вероятность))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcd1710c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>is_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.330467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>0.725477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.240190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>0.536798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.471325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  age   is_male\n",
       "0        6    2  0.330467\n",
       "1       11    5  0.725477\n",
       "2       19    1  0.240190\n",
       "3       27    2  0.536798\n",
       "4       32    3  0.471325"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample_submission.csv\n",
    "# По возрасту классы: Класс 1 —19-25, Класс 2 —26-35, Класс 3 —36-45, Класс 4 —46-55, Класс 5 —56-65, Класс 6— 66+\n",
    "\n",
    "sample_submission = pd.read_csv(f\"{LOCAL_DATA_PATH_mts}/sample_submission.csv\")\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c3cd13",
   "metadata": {},
   "source": [
    "## Заданные id для предсказания.\n",
    "\"id_to_submit\"\n",
    "\n",
    "в этом файле id, по которым нужно предсказать пол и возраст и загрузить submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bea817c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 144724 entries, 0 to 144723\n",
      "Data columns (total 1 columns):\n",
      " #   Column   Non-Null Count   Dtype\n",
      "---  ------   --------------   -----\n",
      " 0   user_id  144724 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 1.1 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144719</th>\n",
       "      <td>415284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144720</th>\n",
       "      <td>415285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144721</th>\n",
       "      <td>415286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144722</th>\n",
       "      <td>415306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144723</th>\n",
       "      <td>415315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id\n",
       "144719   415284\n",
       "144720   415285\n",
       "144721   415286\n",
       "144722   415306\n",
       "144723   415315"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# в этом файле id, по которым нужно предсказать пол и возраст\n",
    "# target_submit = pd.read_parquet('..\\context_data\\submit_2.pqt')\n",
    "\n",
    "id_to_submit = pd.read_parquet(f'{LOCAL_DATA_PATH_mts}/{SUBMIT_FILE}').reset_index(drop=True)\n",
    "id_to_submit.info()\n",
    "id_to_submit.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52218e9",
   "metadata": {},
   "source": [
    "---\n",
    "# Подготовка данных и форматирование."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5544f145",
   "metadata": {},
   "source": [
    "## 1. Подготовка целевых признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fdd49",
   "metadata": {},
   "source": [
    "### 1.1. Первичный взгляд на целевые переменные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4915e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>is_male</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>269995</th>\n",
       "      <td>49.0</td>\n",
       "      <td>1</td>\n",
       "      <td>225374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269996</th>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>25776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269997</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>148131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269998</th>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>205570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269999</th>\n",
       "      <td>68.0</td>\n",
       "      <td>1</td>\n",
       "      <td>103148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         age is_male  user_id\n",
       "269995  49.0       1   225374\n",
       "269996  22.0       1    25776\n",
       "269997  28.0       0   148131\n",
       "269998  28.0       1   205570\n",
       "269999  68.0       1   103148"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = pd.read_parquet(f'{LOCAL_DATA_PATH_mts}/{TARGET_FILE}').reset_index(drop=True)\n",
    "targets.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89289276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 270000 entries, 0 to 269999\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   age      269999 non-null  float64\n",
      " 1   is_male  269958 non-null  object \n",
      " 2   user_id  270000 non-null  int64  \n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 6.2+ MB\n"
     ]
    }
   ],
   "source": [
    "targets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89b97674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age        0.000004\n",
       "is_male    0.000156\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.isna().sum()[targets.isna().sum() > 0] / targets.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cdd8fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         1\n",
       "is_male    42\n",
       "user_id     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afa26623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего 5675 пропусков и незаполненных значений,\n",
      "это 0.021 % от всего Дата Сета \n"
     ]
    }
   ],
   "source": [
    "nan_vals = targets[['age',\n",
    "                   'is_male']][targets.values == 'NA'].value_counts().sum()\n",
    "\n",
    "print(f'Всего {targets.shape[0] - (targets.dropna().shape[0] - nan_vals)} \\\n",
    "пропусков и незаполненных значений,\\nэто \\\n",
    "{round((targets.shape[0] - (targets.dropna().shape[0])+ nan_vals) / targets.shape[0], 3) } \\\n",
    "% от всего Дата Сета ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7893d073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>is_male</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5627</th>\n",
       "      <td>29.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>205306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5628</th>\n",
       "      <td>49.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>95348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5629</th>\n",
       "      <td>49.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>350886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5630</th>\n",
       "      <td>23.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>341849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5631</th>\n",
       "      <td>22.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>208048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age is_male  user_id\n",
       "5627  29.0      NA   205306\n",
       "5628  49.0      NA    95348\n",
       "5629  49.0      NA   350886\n",
       "5630  23.0      NA   341849\n",
       "5631  22.0      NA   208048"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# пропуски наглядно\n",
    "targets[targets.values == 'NA'].reset_index(drop=True).tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7911b3bc",
   "metadata": {},
   "source": [
    "**т.к. в условии задачи классифкация возраста начинается с 19, то просто дропаю всех, кто младше  19**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab15d01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего is_male < 19 = 1077\n"
     ]
    }
   ],
   "source": [
    "print(f\"Всего is_male < 19 = {targets[['age']][targets.age.values < 19].value_counts().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b1e4fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>is_male</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>269995</th>\n",
       "      <td>49.0</td>\n",
       "      <td>1</td>\n",
       "      <td>225374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269996</th>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>25776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269997</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>148131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269998</th>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>205570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269999</th>\n",
       "      <td>68.0</td>\n",
       "      <td>1</td>\n",
       "      <td>103148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         age is_male  user_id\n",
       "269995  49.0       1   225374\n",
       "269996  22.0       1    25776\n",
       "269997  28.0       0   148131\n",
       "269998  28.0       1   205570\n",
       "269999  68.0       1   103148"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = targets.drop(targets.query(\"age < 19\").index)\n",
    "targets.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25e1887a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age        1\n",
       "is_male    0\n",
       "user_id    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "932bfa55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age        0\n",
       "is_male    0\n",
       "user_id    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.dropna(inplace=True)\n",
    "targets.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9be2ff",
   "metadata": {},
   "source": [
    "### 1.2. Разбиваю возраст по классам.\n",
    "targets['age_target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "712cb9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_bucket(x):\n",
    "    \"\"\"\n",
    "    Разбиваем возраст в виде новых классов\n",
    "    \"Класс 1: 19-25,...\"\n",
    "    \"\"\"\n",
    "    return bisect.bisect_left([25,35,45,55,65], x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e956c1",
   "metadata": {},
   "source": [
    "Классификация возрастного признака"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59c5b3fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>is_male</th>\n",
       "      <th>user_id</th>\n",
       "      <th>age_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>350459</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>188276</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "      <td>99002</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>155506</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>213873</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age is_male  user_id  age_target\n",
       "0  31.0       1   350459           1\n",
       "1  35.0       1   188276           1\n",
       "2  41.0       0    99002           2\n",
       "3  33.0       0   155506           1\n",
       "4  54.0       0   213873           3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets['age_target'] = targets['age'].map(age_bucket)\n",
    "targets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68cc5a2",
   "metadata": {},
   "source": [
    "### 1.3. Запись предобработанного таргета."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a31c7a3",
   "metadata": {},
   "source": [
    "Получаю 2 таргета:\n",
    "\n",
    "- targets_age: выходит немного больше, т.к. я не удалял полностью из общего датасета строки с незаполненными значениями в ввиде('NA') в признаке is_male, а лишние данные при обучении не помешают =)\n",
    "- targets_is_male: оставляю только заполненные значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17e46b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>268917</th>\n",
       "      <td>225374</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268918</th>\n",
       "      <td>25776</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268919</th>\n",
       "      <td>148131</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268920</th>\n",
       "      <td>205570</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268921</th>\n",
       "      <td>103148</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  age_target\n",
       "268917   225374           3\n",
       "268918    25776           0\n",
       "268919   148131           1\n",
       "268920   205570           1\n",
       "268921   103148           5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_age = targets[['user_id','age_target']].reset_index(drop=True)\n",
    "targets_age[['age_target']] = targets_age[['age_target']].astype('int8')\n",
    "targets_age.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a04fdde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>is_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>263503</th>\n",
       "      <td>225374</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263504</th>\n",
       "      <td>25776</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263505</th>\n",
       "      <td>148131</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263506</th>\n",
       "      <td>205570</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263507</th>\n",
       "      <td>103148</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  is_male\n",
       "263503   225374        1\n",
       "263504    25776        1\n",
       "263505   148131        0\n",
       "263506   205570        1\n",
       "263507   103148        1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_is_male = targets[['user_id','is_male']]\n",
    "targets_is_male = targets_is_male.drop(\n",
    "                            targets_is_male.query(\n",
    "                                \"is_male == 'NA'\").index).reset_index(drop=True)\n",
    "\n",
    "targets_is_male['is_male'] = targets_is_male['is_male'].astype('int8')\n",
    "targets_is_male.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ac7ddc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "# save new df with targets #\n",
    "############################\n",
    "\n",
    "targets_age.to_parquet(f\"{LOCAL_DATA_PATH}/{PREP_DATA}/targets_age_prep.parquet\")\n",
    "targets_is_male.to_parquet(f\"{LOCAL_DATA_PATH}/{PREP_DATA}/targets_is_male_prep.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c39d70",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9f087c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_targets():\n",
    "    \"\"\"\n",
    "    Функция предобработки таргета\n",
    "    \"\"\"\n",
    "    \n",
    "    #load\n",
    "    targets = pd.read_parquet(f'{LOCAL_DATA_PATH_mts}/{TARGET_FILE}').reset_index(drop=True)\n",
    "\n",
    "    # по условию отбрасываем всех, кто младше 19\n",
    "    targets = targets.drop(targets.query(\"age < 19\").index)\n",
    "\n",
    "    # убираем пропуски\n",
    "    targets.dropna(inplace=True)\n",
    "\n",
    "    # добавляем новый признак с \"классификацией\" возрастов\n",
    "    targets['age_target'] = targets['age'].map(age_bucket)\n",
    "\n",
    "    # targets_age\n",
    "    targets_age = targets[['user_id','age_target']].reset_index(drop=True)\n",
    "    targets_age[['age_target']] = targets_age[['age_target']].astype('int8')\n",
    "\n",
    "    # targets_is_male\n",
    "    targets_is_male = targets[['user_id','is_male']]\n",
    "    targets_is_male = targets_is_male.drop(\n",
    "                                targets_is_male.query(\n",
    "                                    \"is_male == 'NA'\").index).reset_index(drop=True)\n",
    "\n",
    "    targets_is_male['is_male'] = targets_is_male['is_male'].astype('int8')\n",
    "\n",
    "    # saving\n",
    "    targets_age.to_parquet(f\"{LOCAL_DATA_PATH}/{PREP_DATA}/targets_age_prep.parquet\")\n",
    "    targets_is_male.to_parquet(f\"{LOCAL_DATA_PATH}/{PREP_DATA}/targets_is_male_prep.parquet\")\n",
    "    \n",
    "    del targets, targets_age, targets_is_male\n",
    "    gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed9c827e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_targets()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92db9779",
   "metadata": {},
   "source": [
    "## 2. Функции по предобработке данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83643ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['part-00000-aba60f69-2b63-4cc1-95ca-542598094698-c000.snappy.parquet',\n",
       " 'part-00001-aba60f69-2b63-4cc1-95ca-542598094698-c000.snappy.parquet',\n",
       " 'part-00002-aba60f69-2b63-4cc1-95ca-542598094698-c000.snappy.parquet',\n",
       " 'part-00003-aba60f69-2b63-4cc1-95ca-542598094698-c000.snappy.parquet',\n",
       " 'part-00004-aba60f69-2b63-4cc1-95ca-542598094698-c000.snappy.parquet',\n",
       " 'part-00005-aba60f69-2b63-4cc1-95ca-542598094698-c000.snappy.parquet',\n",
       " 'part-00006-aba60f69-2b63-4cc1-95ca-542598094698-c000.snappy.parquet',\n",
       " 'part-00007-aba60f69-2b63-4cc1-95ca-542598094698-c000.snappy.parquet',\n",
       " 'part-00008-aba60f69-2b63-4cc1-95ca-542598094698-c000.snappy.parquet',\n",
       " 'part-00009-aba60f69-2b63-4cc1-95ca-542598094698-c000.snappy.parquet']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part_list = os.listdir(path=f'./{LOCAL_DATA_PATH_mts}/competition_data_final_pqt')\n",
    "part_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2265c4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ = pd.read_parquet(f'{LOCAL_DATA_PATH_mts}/{DATA_FILE}/{part_list[0]}')[:100000]\n",
    "# del df_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317157e5",
   "metadata": {},
   "source": [
    "## 2.1 Функции."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e9b397",
   "metadata": {},
   "source": [
    "В некоторых ф-циях сокращаю типы данных для уменььшения финального размера.\n",
    "\n",
    "Посмотрев, с помощью .describe() несколько файлов, я выбрал int32(Целые числа в диапазоне от -2147483648 по 2147483647, (размером 4 байта)), потому что в файлах не было чисел больше 2млрд"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99d499f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unite_categories(df: pd.core.frame.DataFrame) -> pd.core.frame.DataFrame:\n",
    "    \"\"\"\n",
    "    Ф-ция unite_categories\n",
    "    объединяет повторяющиеся имена производителей смартфонов,\n",
    "    полные названия фирм и названия операционок\n",
    "    \n",
    "    Parametrs \n",
    "    ----------\n",
    "    df - датасет с колонками\n",
    "    'user_id', 'cpe_manufacturer_name', 'cpe_model_os_type'\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Предобработанный датасет c колонками\n",
    "    'user_id', 'cpe_manufacturer_name', 'cpe_model_os_type'\n",
    "\n",
    "    return pd.core.frame.DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    df = df[['user_id', 'cpe_manufacturer_name', 'cpe_model_os_type']]\n",
    "    \n",
    "    df[\"cpe_manufacturer_name\"].replace(\"Huawei Device Company Limited\",\n",
    "                                        \"Huawei\", inplace=True)\n",
    "    df[\"cpe_manufacturer_name\"].replace(\n",
    "        \"Realme Chongqing Mobile Telecommunications Corp Ltd\",\n",
    "        \"Realme\", inplace=True)\n",
    "#     df[\"cpe_manufacturer_name\"].replace(\n",
    "#         \"Realme Mobile Telecommunications (Shenzhen) Co Ltd\",\n",
    "        \"Realme\", inplace=True)\n",
    "    df[\"cpe_manufacturer_name\"].replace(\"Sony Mobile Communications Inc.\",\n",
    "                                        \"Sony\", inplace=True)\n",
    "    df[\"cpe_manufacturer_name\"].replace(\"Honor Device Company Limited\",\n",
    "                                        \"Honor\", inplace=True)\n",
    "    \n",
    "    df[\"cpe_model_os_type\"].replace(\"Apple iOS\",\n",
    "                                    \"iOS\", inplace=True)  \n",
    "    \n",
    "    df = df.drop_duplicates(subset=['user_id'])\n",
    "    \n",
    "    gc.collect() \n",
    "    print('unite_categories done')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a2bb9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparation_numbers(df: pd.core.frame.DataFrame) -> pd.core.frame.DataFrame:\n",
    "    \"\"\"\n",
    "    Ф-ция preparation_numbers\n",
    "    заполняет пропуски стоимости ус-ва,\n",
    "    создаёт новые признаки частей дня\n",
    "    и подсчитывает общее количество переходов по ссылкам\n",
    "    для новых признаков по каждому user_id\n",
    "    \n",
    "    Parametrs \n",
    "    ----------\n",
    "     df - датасет с колонками\n",
    "     'price','part_of_day','request_cnt','user_id'\n",
    "     \n",
    "    Returns\n",
    "    -------\n",
    "    Предобработанный датасет c нов. колонками\n",
    "    'price', 'user_id', 'day', 'evening', 'morning', 'night'\n",
    "    \n",
    "    return pd.core.frame.DataFrame\n",
    "    \"\"\"    \n",
    "\n",
    "    # отбор нужных признаков\n",
    "    df = df[['price','part_of_day','request_cnt','user_id']]\n",
    "    \n",
    "    # Заполнение пропусков стоимости медианой\n",
    "    df[\"price\"] = df[\"price\"].fillna(np.nanmedian(df[\"price\"].values))    \n",
    "    \n",
    "    # Создание новых признаков с общим количеством запросов URL в опред. части дня\n",
    "    df_part_of_day = df.pivot_table(index='user_id',\n",
    "                                    columns='part_of_day',\n",
    "                                    values='request_cnt',\n",
    "                                    aggfunc='count'\n",
    "                                   ).reset_index().fillna(0)\n",
    "\n",
    "    df = df.merge(df_part_of_day, how=\"inner\", on=[\"user_id\"])\n",
    "    \n",
    "    df = df.drop_duplicates(subset=['user_id'])\n",
    "    df = df.drop(columns=['part_of_day','request_cnt'], axis=1)\n",
    "    \n",
    "    gc.collect()\n",
    "    print('preparation_numbers done')\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24f32f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_day_names(df: pd.core.frame.DataFrame) -> pd.core.frame.DataFrame:\n",
    "    \"\"\"\n",
    "    Ф-ция add_day_names\n",
    "    создает новые признаки и превращает даты в дни недели,\n",
    "    подсчитывает количество переходов по ссылкам\n",
    "    в день недели по каждому user_id\n",
    "    \n",
    "    Parametrs \n",
    "    ----------     \n",
    "    df - датасет с колонками\n",
    "    'date','request_cnt','user_id'\n",
    "     \n",
    "    Returns\n",
    "    -------\n",
    "    Предобработанный датасет c нов. колонками\n",
    "    'user_id' 'fri' 'mon' 'sat' 'sun' 'thu' 'tue' 'wed'\n",
    "\n",
    "    return pd.core.frame.DataFrame     \n",
    "    \"\"\"\n",
    "    \n",
    "    df = df[['date','request_cnt','user_id']]\n",
    "    \n",
    "    df['day_name'] = df['date'].apply( lambda x: x.strftime('%a').lower())\n",
    "\n",
    "    df = df.pivot_table(index='user_id',\n",
    "                                 columns='day_name',\n",
    "                                 values='request_cnt', # ?\n",
    "                                 aggfunc='count').reset_index().fillna(0)\n",
    "\n",
    "    gc.collect()\n",
    "    print('add_day_names done')\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0cfdabc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_url_filter(df: pd.core.frame.DataFrame, n=100) -> pd.core.frame.DataFrame:\n",
    "    \"\"\"\n",
    "    Ф-ция top_url_filter\n",
    "    1) слежение за id_to_submit в текущем df\n",
    "    что бы не потерять нужные submit_id\n",
    "    2) Подсчёт кол-ва переходов по url в текущем df\n",
    "    3) отбор самых запрашиваемых URL\n",
    "    где кол-во переходов по url > n раз.\n",
    "    4) оставляем в рабочем датасете только топовые URL\n",
    "    5) создаём датасет, где 1 строка это 1 id и все топовыве URL в виде новых признаков\n",
    "    6) проверка получившегося датасета на пропуски submit_id по 1ому шагу\n",
    "    \n",
    "    Parametrs \n",
    "    ----------\n",
    "    submit_size - количество id_to_submit в текущем df\n",
    "    filtering_df - df с урлами и ощим кол-вом переходов по ним\n",
    "    top_urls - df c отфильтрованными url\n",
    "    df_new - df где сначала оставляем только топовые url, а потом \n",
    "    деламе из них новыве признаки\n",
    "    \n",
    "    фильтрация незначительных URL\n",
    "    \n",
    "    df - \n",
    "     \n",
    "    Returns\n",
    "    -------\n",
    "    Предобработанный датасет c нов. колонками\n",
    "    'user_id' и много url в виде признаков\n",
    "\n",
    "    return pd.core.frame.DataFrame     \n",
    "    \"\"\"\n",
    "    \n",
    "    print('top_url_filter start')\n",
    "    \n",
    "    # n_filter 50 = 5024 columns не хватает памяти для склейки всех df\n",
    "    # n_filter 70 = 4030 columns\n",
    "    # n_filter 100 = 3086 columns\n",
    "    # n_filter 130 = 2609 columns\n",
    "    n_filter = int(n)\n",
    "    \n",
    "    # 1)\n",
    "    submit_size = df.merge(id_to_submit,\n",
    "                          how=\"inner\",\n",
    "                          on=[\"user_id\"]).drop_duplicates(subset=['user_id']).shape[0]\n",
    "    print(f\"-submits in curr dataset {submit_size}\")\n",
    "    \n",
    "    \n",
    "    # 2)\n",
    "    filtering_df = df['url_host'].value_counts().reset_index(name='url_count')\n",
    "    filtering_df.rename(columns = {'index' : 'url_host'}, inplace = True)\n",
    "    \n",
    "    # 3)\n",
    "    top_urls = filtering_df[filtering_df['url_count'] > n_filter].drop(columns=['url_count'], axis=1)\n",
    "    \n",
    "    \n",
    "    # костыль обыкновенный! отобранные вручную мусорные ключевые значения: \n",
    "    # реклама, баннеры, статистики и прочее\n",
    "    # убирает некоторые сабмит id\n",
    "#     top_urls = top_urls[top_urls[\"url_host\"].str\n",
    "#                             .contains(\"1|2|3|4|5|6|7|8|9|0|info|stream|cloud|map|site|fss|adhigh|qq|\\\n",
    "#                                       static|backbook|lk.|thealloha|.online|tinyurl|muzmo|zagonko|\\\n",
    "#                                       stories|club|duck|xml|syndicat|platform|blocked|viiadr|traffic|\\\n",
    "#                                       mycdn|cdn|hd.|mp3|link|webattach|interesbook|index|help|comment|\\\n",
    "#                                       quickaccess|dud|alloha|appnext|banners|ssp|adfox|relap|srv|google|\\\n",
    "#                                       api|-|sun9|userapi|advert|ad.|away.|metrics|metrika|img|betweendigital|\\\n",
    "#                                       bigo|payments|recommend|microsoft|viewer|block|auth|cootek|turbopages|\\\n",
    "#                                       doubleclick|avatars|promo|adriver|BUZZOOLA|buzzoola|req.|cpg|startapp|\\\n",
    "#                                       dan.com|ooo|optnx|kodik|feedburner|aniqit|app.|player|login|widget|\\\n",
    "#                                       tevas|video|wiki\")== False]\n",
    "\n",
    "    top_urls = top_urls[top_urls[\"url_host\"].str\n",
    "                            .contains(\"--\")== False]\n",
    "\n",
    "\n",
    "    # 4)\n",
    "    df_new = df.merge(top_urls, how='inner', on=[\"url_host\"])\n",
    "\n",
    "    # 5)\n",
    "    df_new = df_new.pivot_table(index='user_id',\n",
    "                                    columns='url_host',\n",
    "                                    values='request_cnt',\n",
    "                                    aggfunc='count').reset_index().fillna(0)\n",
    "\n",
    "    print(f\"-df_new with top_url {df_new.shape}\")\n",
    "    \n",
    "    # 6) проверяем получившийся df на пропуски submit_id\n",
    "    new_submit = df_new.merge(id_to_submit, how=\"inner\", on=[\"user_id\"]).shape[0]\n",
    "    print(f\"-new_submit.shape {new_submit}\")\n",
    "    \n",
    "    # если вдруг потеряется submit_id, то уменьшаем n_filter  \n",
    "    # и submit_id может появиться\n",
    "    while submit_size != new_submit:\n",
    "        n/= 1.3\n",
    "        top_url_filter(df,n)\n",
    "\n",
    "    gc.collect()\n",
    "    print(f\"top_url_filter done\\n\")\n",
    "    \n",
    "    return(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "25d4a504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top = top_url_filter(df_, 75)\n",
    "# top"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430314cb",
   "metadata": {},
   "source": [
    "### 2.2. Цикл предобработки и сохранения всех частей данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a3f67717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preparation part 0\n",
      "loaded df.shape (32638709, 12)\n",
      "\n",
      "unite_cathegories done\n",
      "preparation_numbers done\n",
      "add_day_names done\n",
      "top_url_filter start\n",
      "-submits in curr dataset 14368\n",
      "-df_new with top_url (41593, 4030)\n",
      "-new_submit.shape 14368\n",
      "top_url_filter done\n",
      "\n",
      "merge done\n",
      "df.isna 0\n",
      "\n",
      "preprocessed_data_part_0 shape (41593, 4044)\n",
      "save on disc.\n",
      "-------------\n",
      "\n",
      "Data preparation part 1\n",
      "loaded df.shape (32423119, 12)\n",
      "\n",
      "unite_cathegories done\n",
      "preparation_numbers done\n",
      "add_day_names done\n",
      "top_url_filter start\n",
      "-submits in curr dataset 14463\n",
      "-df_new with top_url (41569, 3975)\n",
      "-new_submit.shape 14463\n",
      "top_url_filter done\n",
      "\n",
      "merge done\n",
      "df.isna 0\n",
      "\n",
      "preprocessed_data_part_1 shape (41569, 3989)\n",
      "save on disc.\n",
      "-------------\n",
      "\n",
      "Data preparation part 2\n",
      "loaded df.shape (32146620, 12)\n",
      "\n",
      "unite_cathegories done\n",
      "preparation_numbers done\n",
      "add_day_names done\n",
      "top_url_filter start\n",
      "-submits in curr dataset 14366\n",
      "-df_new with top_url (41334, 3935)\n",
      "-new_submit.shape 14366\n",
      "top_url_filter done\n",
      "\n",
      "merge done\n",
      "df.isna 0\n",
      "\n",
      "preprocessed_data_part_2 shape (41334, 3949)\n",
      "save on disc.\n",
      "-------------\n",
      "\n",
      "Data preparation part 3\n",
      "loaded df.shape (32156858, 12)\n",
      "\n",
      "unite_cathegories done\n",
      "preparation_numbers done\n",
      "add_day_names done\n",
      "top_url_filter start\n",
      "-submits in curr dataset 14572\n",
      "-df_new with top_url (41638, 3917)\n",
      "-new_submit.shape 14572\n",
      "top_url_filter done\n",
      "\n",
      "merge done\n",
      "df.isna 0\n",
      "\n",
      "preprocessed_data_part_3 shape (41638, 3931)\n",
      "save on disc.\n",
      "-------------\n",
      "\n",
      "Data preparation part 4\n",
      "loaded df.shape (32119163, 12)\n",
      "\n",
      "unite_cathegories done\n",
      "preparation_numbers done\n",
      "add_day_names done\n",
      "top_url_filter start\n",
      "-submits in curr dataset 14315\n",
      "-df_new with top_url (41285, 3901)\n",
      "-new_submit.shape 14315\n",
      "top_url_filter done\n",
      "\n",
      "merge done\n",
      "df.isna 0\n",
      "\n",
      "preprocessed_data_part_4 shape (41285, 3915)\n",
      "save on disc.\n",
      "-------------\n",
      "\n",
      "Data preparation part 5\n",
      "loaded df.shape (32300908, 12)\n",
      "\n",
      "unite_cathegories done\n",
      "preparation_numbers done\n",
      "add_day_names done\n",
      "top_url_filter start\n",
      "-submits in curr dataset 14426\n",
      "-df_new with top_url (41576, 3926)\n",
      "-new_submit.shape 14426\n",
      "top_url_filter done\n",
      "\n",
      "merge done\n",
      "df.isna 0\n",
      "\n",
      "preprocessed_data_part_5 shape (41576, 3940)\n",
      "save on disc.\n",
      "-------------\n",
      "\n",
      "Data preparation part 6\n",
      "loaded df.shape (32134423, 12)\n",
      "\n",
      "unite_cathegories done\n",
      "preparation_numbers done\n",
      "add_day_names done\n",
      "top_url_filter start\n",
      "-submits in curr dataset 14485\n",
      "-df_new with top_url (41460, 3919)\n",
      "-new_submit.shape 14485\n",
      "top_url_filter done\n",
      "\n",
      "merge done\n",
      "df.isna 0\n",
      "\n",
      "preprocessed_data_part_6 shape (41460, 3933)\n",
      "save on disc.\n",
      "-------------\n",
      "\n",
      "Data preparation part 7\n",
      "loaded df.shape (32523675, 12)\n",
      "\n",
      "unite_cathegories done\n",
      "preparation_numbers done\n",
      "add_day_names done\n",
      "top_url_filter start\n",
      "-submits in curr dataset 14616\n",
      "-df_new with top_url (41611, 4029)\n",
      "-new_submit.shape 14616\n",
      "top_url_filter done\n",
      "\n",
      "merge done\n",
      "df.isna 0\n",
      "\n",
      "preprocessed_data_part_7 shape (41611, 4043)\n",
      "save on disc.\n",
      "-------------\n",
      "\n",
      "Data preparation part 8\n",
      "loaded df.shape (32136680, 12)\n",
      "\n",
      "unite_cathegories done\n",
      "preparation_numbers done\n",
      "add_day_names done\n",
      "top_url_filter start\n",
      "-submits in curr dataset 14623\n",
      "-df_new with top_url (41682, 3831)\n",
      "-new_submit.shape 14623\n",
      "top_url_filter done\n",
      "\n",
      "merge done\n",
      "df.isna 0\n",
      "\n",
      "preprocessed_data_part_8 shape (41682, 3845)\n",
      "save on disc.\n",
      "-------------\n",
      "\n",
      "Data preparation part 9\n",
      "loaded df.shape (32319280, 12)\n",
      "\n",
      "unite_cathegories done\n",
      "preparation_numbers done\n",
      "add_day_names done\n",
      "top_url_filter start\n",
      "-submits in curr dataset 14490\n",
      "-df_new with top_url (41559, 3958)\n",
      "-new_submit.shape 14490\n",
      "top_url_filter done\n",
      "\n",
      "merge done\n",
      "df.isna 0\n",
      "\n",
      "preprocessed_data_part_9 shape (41559, 3972)\n",
      "save on disc.\n",
      "-------------\n",
      "\n",
      "Number of submissions match the submissions in the prepared data?\n",
      "144724 == 144724\n",
      "True\n",
      "Data preparation completed successfully\n",
      "Wall time: 30min 27s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "prep_df_with_submit = 0\n",
    "\n",
    "for i in range(len(part_list)):\n",
    "    print(f'Data preparation part {i}')\n",
    "    \n",
    "    # чтение данных\n",
    "    temp_df = pd.read_parquet(f'{LOCAL_DATA_PATH_mts}/{DATA_FILE}/{part_list[i]}')\n",
    "    print(f\"loaded df.shape {temp_df.shape}\\n\")\n",
    "\n",
    "    # 1) Подготовка категориальных признаков и частей дня\n",
    "    prep_cat = unite_categories(temp_df)\n",
    "    \n",
    "    # 2) Подготовка числовых признаков\n",
    "    prep_nums = preparation_numbers(temp_df)\n",
    "\n",
    "    # 3) Подготовка признаков от даты ко дню недели\n",
    "    prep_days = add_day_names(temp_df)\n",
    "    \n",
    "    # 4) Отбор самых запрашиваемых URL\n",
    "    prep_url = top_url_filter(temp_df, 70)\n",
    "    \n",
    "    # Объединение подготовленных данных по id\n",
    "    merge1 = prep_cat.merge(prep_nums, how=\"inner\", on=[\"user_id\"])\n",
    "    merge2 = merge1.merge(prep_days, how=\"inner\", on=[\"user_id\"])\n",
    "    \n",
    "    temp_df = prep_url.merge(merge2, how=\"inner\", on=[\"user_id\"])\n",
    "    print(\"merge done\")\n",
    "    print(f\"df.isna {temp_df.isna().sum().sum()}\\n\")\n",
    "    \n",
    "    \n",
    "    # Запись подготовленного датасета в файл\n",
    "    temp_df.to_parquet(f\"{LOCAL_DATA_PATH}/{PREP_DATA}//preprocessed_part_{i}.parquet\")\n",
    "    \n",
    "    # Проверка на потерю сабмитов после отбора признаков\n",
    "    prep_df_with_submit += temp_df.merge(id_to_submit,\n",
    "                                        how=\"inner\",\n",
    "                                        on=[\"user_id\"]\n",
    "                                       ).drop_duplicates(subset=[\"user_id\"]).shape[0]\n",
    "    \n",
    "    print(f\"preprocessed_data_part_{i} shape {temp_df.shape}\\nsave on disc.\")\n",
    "    print(\"-------------\\n\")\n",
    "    \n",
    "\n",
    "if id_to_submit.shape[0] == prep_df_with_submit:\n",
    "    print(\"Number of submissions match the submissions in the prepared data?\")\n",
    "    print(f\"{id_to_submit.shape[0]} == {prep_df_with_submit}\") \n",
    "    print(f\"{id_to_submit.shape[0] == prep_df_with_submit}\")    \n",
    "    print(\"Data preparation completed successfully\")\n",
    "else:\n",
    "    print(\"Data preparation is not satisfactory, try changing the preparation settings\")\n",
    "\n",
    "del prep_cat, prep_nums, prep_days, prep_url, merge1, merge2, temp_df, prep_df_with_submit\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e4ff9f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e485271c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data_parts():\n",
    "    \"\"\"\n",
    "    ф-ция предобработки и сохранения данных.\n",
    "    \"\"\"\n",
    "    \n",
    "    id_to_submit = pd.read_parquet(f'{LOCAL_DATA_PATH_mts}/{SUBMIT_FILE}').reset_index(drop=True)\n",
    "    \n",
    "    prep_df_with_submit = 0 # счётчик\n",
    "    \n",
    "    # Цикл предобработки и сохранения всех частей данных.\n",
    "    for i in range(len(part_list)):\n",
    "        print(f'Data preparation part {i+1}/10')\n",
    "\n",
    "        # чтение данных\n",
    "        temp_df = pd.read_parquet(f'{LOCAL_DATA_PATH_mts}/{DATA_FILE}/{part_list[i]}')\n",
    "        print(f\"loaded df.shape {temp_df.shape}\\n\")\n",
    "\n",
    "        # 1) Подготовка категориальных признаков и частей дня\n",
    "        prep_cat = unite_categories(temp_df)\n",
    "\n",
    "        # 2) Подготовка числовых признаков\n",
    "        prep_nums = preparation_numbers(temp_df)\n",
    "\n",
    "        # 3) Подготовка признаков от даты ко дню недели\n",
    "        prep_days = add_day_names(temp_df)\n",
    "\n",
    "        # 4) Отбор самых запрашиваемых URL\n",
    "        prep_url = top_url_filter(temp_df, 70)\n",
    "\n",
    "        # Объединение подготовленных данных по id\n",
    "        merge1 = prep_cat.merge(prep_nums, how=\"inner\", on=[\"user_id\"])\n",
    "        merge2 = merge1.merge(prep_days, how=\"inner\", on=[\"user_id\"])\n",
    "\n",
    "        temp_df = prep_url.merge(merge2, how=\"inner\", on=[\"user_id\"])\n",
    "        print(\"merge done\")\n",
    "        print(f\"df.isna {temp_df.isna().sum().sum()}\\n\")\n",
    "\n",
    "        # Запись подготовленного датасета в файл\n",
    "        temp_df.to_parquet(f\"{LOCAL_DATA_PATH}/{PREP_DATA}//preprocessed_part_{i}.parquet\")\n",
    "\n",
    "        # отслежиание за отсутствием потерей сабмитов после отбора признаков\n",
    "        prep_df_with_submit += temp_df.merge(id_to_submit,\n",
    "                                            how=\"inner\",\n",
    "                                            on=[\"user_id\"]\n",
    "                                           ).drop_duplicates(subset=[\"user_id\"]).shape[0]\n",
    "\n",
    "        print(f\"preprocessed_data_part_{i} shape {temp_df.shape}\\nsave on disc.\")\n",
    "        print(\"-------------\\n\")\n",
    "        \n",
    "        del temp_df, prep_cat, prep_nums, prep_days, prep_url, merge1, merge2\n",
    "\n",
    "    if id_to_submit.shape[0] == prep_df_with_submit:\n",
    "        print(\"Number of submissions match the submissions in the prepared data?\")\n",
    "        print(f\"{id_to_submit.shape[0]} == {prep_df_with_submit}\") \n",
    "        print(f\"{id_to_submit.shape[0] == prep_df_with_submit}\")    \n",
    "        print(\"Data preparation completed successfully\")\n",
    "    else:\n",
    "        print(\"Data preparation is not satisfactory, try changing the preparation settings\")\n",
    "\n",
    "#     del prep_cat, prep_nums, prep_days, prep_url, merge1, merge2, temp_df, prep_df_with_submit\n",
    "    del prep_df_with_submit, id_to_submit\n",
    "\n",
    "    gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37d9de65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preparation part 1/10\n",
      "loaded df.shape (32638709, 12)\n",
      "\n",
      "unite_categories done\n",
      "preparation_numbers done\n",
      "add_day_names done\n",
      "top_url_filter start\n",
      "-submits in curr dataset 14368\n",
      "-df_new with top_url (41593, 4030)\n",
      "-new_submit.shape 14368\n",
      "top_url_filter done\n",
      "\n",
      "merge done\n",
      "df.isna 0\n",
      "\n",
      "preprocessed_data_part_0 shape (41593, 4044)\n",
      "save on disc.\n",
      "-------------\n",
      "\n",
      "Data preparation part 2/10\n",
      "loaded df.shape (32423119, 12)\n",
      "\n",
      "unite_categories done\n",
      "preparation_numbers done\n",
      "add_day_names done\n",
      "top_url_filter start\n",
      "-submits in curr dataset 14463\n",
      "-df_new with top_url (41569, 3975)\n",
      "-new_submit.shape 14463\n",
      "top_url_filter done\n",
      "\n",
      "merge done\n",
      "df.isna 0\n",
      "\n",
      "preprocessed_data_part_1 shape (41569, 3989)\n",
      "save on disc.\n",
      "-------------\n",
      "\n",
      "Data preparation part 3/10\n",
      "loaded df.shape (32146620, 12)\n",
      "\n",
      "unite_categories done\n",
      "preparation_numbers done\n",
      "add_day_names done\n",
      "top_url_filter start\n",
      "-submits in curr dataset 14366\n",
      "-df_new with top_url (41334, 3935)\n",
      "-new_submit.shape 14366\n",
      "top_url_filter done\n",
      "\n",
      "merge done\n",
      "df.isna 0\n",
      "\n",
      "preprocessed_data_part_2 shape (41334, 3949)\n",
      "save on disc.\n",
      "-------------\n",
      "\n",
      "Data preparation part 4/10\n",
      "loaded df.shape (32156858, 12)\n",
      "\n",
      "unite_categories done\n",
      "preparation_numbers done\n",
      "add_day_names done\n",
      "top_url_filter start\n",
      "-submits in curr dataset 14572\n",
      "-df_new with top_url (41638, 3917)\n",
      "-new_submit.shape 14572\n",
      "top_url_filter done\n",
      "\n",
      "merge done\n",
      "df.isna 0\n",
      "\n",
      "preprocessed_data_part_3 shape (41638, 3931)\n",
      "save on disc.\n",
      "-------------\n",
      "\n",
      "Data preparation part 5/10\n",
      "loaded df.shape (32119163, 12)\n",
      "\n",
      "unite_categories done\n",
      "preparation_numbers done\n",
      "add_day_names done\n",
      "top_url_filter start\n",
      "-submits in curr dataset 14315\n",
      "-df_new with top_url (41285, 3901)\n",
      "-new_submit.shape 14315\n",
      "top_url_filter done\n",
      "\n",
      "merge done\n",
      "df.isna 0\n",
      "\n",
      "preprocessed_data_part_4 shape (41285, 3915)\n",
      "save on disc.\n",
      "-------------\n",
      "\n",
      "Data preparation part 6/10\n",
      "loaded df.shape (32300908, 12)\n",
      "\n",
      "unite_categories done\n",
      "preparation_numbers done\n",
      "add_day_names done\n",
      "top_url_filter start\n",
      "-submits in curr dataset 14426\n",
      "-df_new with top_url (41576, 3926)\n",
      "-new_submit.shape 14426\n",
      "top_url_filter done\n",
      "\n",
      "merge done\n",
      "df.isna 0\n",
      "\n",
      "preprocessed_data_part_5 shape (41576, 3940)\n",
      "save on disc.\n",
      "-------------\n",
      "\n",
      "Data preparation part 7/10\n",
      "loaded df.shape (32134423, 12)\n",
      "\n",
      "unite_categories done\n",
      "preparation_numbers done\n",
      "add_day_names done\n",
      "top_url_filter start\n",
      "-submits in curr dataset 14485\n",
      "-df_new with top_url (41460, 3919)\n",
      "-new_submit.shape 14485\n",
      "top_url_filter done\n",
      "\n",
      "merge done\n",
      "df.isna 0\n",
      "\n",
      "preprocessed_data_part_6 shape (41460, 3933)\n",
      "save on disc.\n",
      "-------------\n",
      "\n",
      "Data preparation part 8/10\n",
      "loaded df.shape (32523675, 12)\n",
      "\n",
      "unite_categories done\n",
      "preparation_numbers done\n",
      "add_day_names done\n",
      "top_url_filter start\n",
      "-submits in curr dataset 14616\n",
      "-df_new with top_url (41611, 4029)\n",
      "-new_submit.shape 14616\n",
      "top_url_filter done\n",
      "\n",
      "merge done\n",
      "df.isna 0\n",
      "\n",
      "preprocessed_data_part_7 shape (41611, 4043)\n",
      "save on disc.\n",
      "-------------\n",
      "\n",
      "Data preparation part 9/10\n",
      "loaded df.shape (32136680, 12)\n",
      "\n",
      "unite_categories done\n",
      "preparation_numbers done\n",
      "add_day_names done\n",
      "top_url_filter start\n",
      "-submits in curr dataset 14623\n",
      "-df_new with top_url (41682, 3831)\n",
      "-new_submit.shape 14623\n",
      "top_url_filter done\n",
      "\n",
      "merge done\n",
      "df.isna 0\n",
      "\n",
      "preprocessed_data_part_8 shape (41682, 3845)\n",
      "save on disc.\n",
      "-------------\n",
      "\n",
      "Data preparation part 10/10\n",
      "loaded df.shape (32319280, 12)\n",
      "\n",
      "unite_categories done\n",
      "preparation_numbers done\n",
      "add_day_names done\n",
      "top_url_filter start\n",
      "-submits in curr dataset 14490\n",
      "-df_new with top_url (41559, 3958)\n",
      "-new_submit.shape 14490\n",
      "top_url_filter done\n",
      "\n",
      "merge done\n",
      "df.isna 0\n",
      "\n",
      "preprocessed_data_part_9 shape (41559, 3972)\n",
      "save on disc.\n",
      "-------------\n",
      "\n",
      "Number of submissions match the submissions in the prepared data?\n",
      "144724 == 144724\n",
      "True\n",
      "Data preparation completed successfully\n"
     ]
    }
   ],
   "source": [
    "prep_data_parts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c4a4ae",
   "metadata": {},
   "source": [
    "## 3. Cоздание общего датасета для обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532587e7",
   "metadata": {},
   "source": [
    "### 3.1.  Cоединение всех частей в единый датасет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bb7882ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_data_dir  = os.listdir(path=f'./{LOCAL_DATA_PATH}/preprocessed_data')\n",
    "# list_data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c400b55a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['preprocessed_part_0.parquet',\n",
       " 'preprocessed_part_1.parquet',\n",
       " 'preprocessed_part_2.parquet',\n",
       " 'preprocessed_part_3.parquet',\n",
       " 'preprocessed_part_4.parquet',\n",
       " 'preprocessed_part_5.parquet',\n",
       " 'preprocessed_part_6.parquet',\n",
       " 'preprocessed_part_7.parquet',\n",
       " 'preprocessed_part_8.parquet',\n",
       " 'preprocessed_part_9.parquet']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_data_prep = []\n",
    "\n",
    "for i in range(len(list_data_dir)):\n",
    "    if 'preprocessed_part' in list_data_dir[i]:\n",
    "        list_data_prep.append(list_data_dir[i])\n",
    "        \n",
    "list_data_prep        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "86645f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>-1</th>\n",
       "      <th>03online.com</th>\n",
       "      <th>1</th>\n",
       "      <th>1000.menu</th>\n",
       "      <th>1000bankov.ru</th>\n",
       "      <th>1001goroskop.ru</th>\n",
       "      <th>100biografiy.ru</th>\n",
       "      <th>100cards.ru</th>\n",
       "      <th>100realt.ru</th>\n",
       "      <th>...</th>\n",
       "      <th>evening</th>\n",
       "      <th>morning</th>\n",
       "      <th>night</th>\n",
       "      <th>fri</th>\n",
       "      <th>mon</th>\n",
       "      <th>sat</th>\n",
       "      <th>sun</th>\n",
       "      <th>thu</th>\n",
       "      <th>tue</th>\n",
       "      <th>wed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>136.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>137.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>347.0</td>\n",
       "      <td>453.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>292.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>786.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>307.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>146.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41564</th>\n",
       "      <td>415279</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41565</th>\n",
       "      <td>415294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41566</th>\n",
       "      <td>415299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41567</th>\n",
       "      <td>415301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41568</th>\n",
       "      <td>415313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41569 rows × 3989 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id   -1  03online.com    1  1000.menu  1000bankov.ru  \\\n",
       "0            7  0.0           0.0  0.0        0.0            0.0   \n",
       "1           11  0.0           0.0  0.0        0.0            0.0   \n",
       "2           39  0.0           0.0  0.0        0.0            0.0   \n",
       "3           49  0.0           0.0  0.0        1.0            0.0   \n",
       "4           51  0.0           0.0  0.0        1.0            0.0   \n",
       "...        ...  ...           ...  ...        ...            ...   \n",
       "41564   415279  0.0           0.0  0.0        0.0            0.0   \n",
       "41565   415294  0.0           0.0  0.0        0.0            0.0   \n",
       "41566   415299  0.0           0.0  0.0        0.0            0.0   \n",
       "41567   415301  0.0           0.0  0.0        0.0            0.0   \n",
       "41568   415313  0.0           0.0  0.0        0.0            0.0   \n",
       "\n",
       "       1001goroskop.ru  100biografiy.ru  100cards.ru  100realt.ru  ...  \\\n",
       "0                  0.0              0.0          0.0          0.0  ...   \n",
       "1                  0.0              0.0          0.0          0.0  ...   \n",
       "2                  0.0              0.0          0.0          0.0  ...   \n",
       "3                  0.0              0.0          0.0          0.0  ...   \n",
       "4                  0.0              0.0          0.0          0.0  ...   \n",
       "...                ...              ...          ...          ...  ...   \n",
       "41564              0.0              0.0          0.0          0.0  ...   \n",
       "41565              0.0              0.0          0.0          0.0  ...   \n",
       "41566              0.0              0.0          0.0          0.0  ...   \n",
       "41567              0.0              0.0          0.0          0.0  ...   \n",
       "41568              0.0              0.0          0.0          0.0  ...   \n",
       "\n",
       "       evening  morning  night    fri    mon    sat    sun    thu    tue  \\\n",
       "0        136.0    114.0  146.0   72.0   26.0   65.0   56.0   81.0   66.0   \n",
       "1         53.0    222.0   10.0   79.0   86.0   59.0   18.0   94.0   98.0   \n",
       "2        347.0    453.0   28.0  203.0  236.0  107.0   63.0  312.0  158.0   \n",
       "3        786.0    330.0  113.0  221.0  246.0  184.0  161.0  320.0  209.0   \n",
       "4        146.0    104.0   32.0   80.0   47.0   82.0   81.0   80.0   47.0   \n",
       "...        ...      ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "41564      0.0      0.0    3.0    0.0    0.0    3.0    3.0    0.0    0.0   \n",
       "41565      0.0      1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "41566      0.0      2.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "41567      1.0      5.0    0.0    0.0    0.0    0.0    0.0    0.0    6.0   \n",
       "41568      0.0      0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0   \n",
       "\n",
       "         wed  \n",
       "0       95.0  \n",
       "1      137.0  \n",
       "2      292.0  \n",
       "3      307.0  \n",
       "4       43.0  \n",
       "...      ...  \n",
       "41564    0.0  \n",
       "41565    1.0  \n",
       "41566    2.0  \n",
       "41567    0.0  \n",
       "41568    0.0  \n",
       "\n",
       "[41569 rows x 3989 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# temp_df = pd.read_parquet(f'{LOCAL_DATA_PATH}/{PREP_DATA}/{list_data_prep[i]}')\n",
    "\n",
    "pd.read_parquet(f'{LOCAL_DATA_PATH}/{PREP_DATA}/{list_data_prep[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7ce65e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded prep part 0\n",
      "Loaded prep part 1\n",
      "Loaded prep part 2\n",
      "Loaded prep part 3\n",
      "Loaded prep part 4\n",
      "Loaded prep part 5\n",
      "Loaded prep part 6\n",
      "Loaded prep part 7\n",
      "Loaded prep part 8\n",
      "Loaded prep part 9\n",
      "\n",
      "concat (415307, 6137)\n",
      "all_df.isna() = 905735976\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 415307 entries, 0 to 415306\n",
      "Columns: 6137 entries, user_id to znamenitosti.info\n",
      "dtypes: float64(3175), int32(2960), object(2)\n",
      "memory usage: 14.4+ GB\n",
      "\n",
      "fillna\n",
      "all_df.isna() = 0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 415307 entries, 0 to 415306\n",
      "Columns: 6137 entries, user_id to znamenitosti.info\n",
      "dtypes: float64(3175), int32(2960), object(2)\n",
      "memory usage: 14.4+ GB\n",
      "\n",
      "astype(np.int32) + .astype('category')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 415307 entries, 0 to 415306\n",
      "Columns: 6137 entries, user_id to znamenitosti.info\n",
      "dtypes: category(2), int32(6135)\n",
      "memory usage: 9.5 GB\n",
      "all_prep_data was saved to file successfully\n",
      "Wall time: 3min 35s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "all_prep_parts = []\n",
    "size = 0\n",
    "\n",
    "for i in range(len(list_data_prep)):\n",
    "    print(f'Loaded prep part {i}')\n",
    "    # Чтение\n",
    "    temp_df = pd.read_parquet(f'{LOCAL_DATA_PATH}/{PREP_DATA}/{list_data_prep[i]}')\n",
    "    \n",
    "    # Уменшение памяти\n",
    "    temp_df = temp_df.astype(np.int32(0), errors='ignore')\n",
    "\n",
    "    all_prep_parts.append(temp_df) \n",
    "    \n",
    "# Соединение всех частей\n",
    "all_df = pd.concat(all_prep_parts, ignore_index = True)\n",
    "print(f'\\nconcat {all_df.shape}\\nall_df.isna() = {all_df.isna().sum().sum()}')\n",
    "all_df.info()\n",
    "\n",
    "all_df = all_df.fillna(value=np.int32(0))\n",
    "print(f'\\nfillna\\nall_df.isna() = {all_df.isna().sum().sum()}')\n",
    "all_df.info()\n",
    "\n",
    "all_df = all_df.astype(np.int32, errors='ignore')\n",
    "all_df[['cpe_manufacturer_name',\n",
    "        'cpe_model_os_type']] = all_df[['cpe_manufacturer_name',\n",
    "                                        'cpe_model_os_type']].astype('category')\n",
    "print(f\"\\nastype(np.int32) + .astype('category')\")\n",
    "all_df.info()\n",
    "\n",
    "# Запись подготовленного общего датасета в файл\n",
    "all_df.to_parquet(f\"{LOCAL_DATA_PATH}/{PREP_DATA}/all_prep_data.parquet\")\n",
    "print('all_prep_data was saved to file successfully')\n",
    "\n",
    "del temp_df, all_df\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265812f3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3ce59f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_parts():\n",
    "    \"\"\"\n",
    "    требуется много оператиной памяти (32гб + 60гб виртуальной)\n",
    "    рекомендую использовать уже объединенные данные\n",
    "    \"\"\"\n",
    "    \n",
    "    # load\n",
    "    list_data_dir  = os.listdir(path=f'./{LOCAL_DATA_PATH}/preprocessed_data')\n",
    "    \n",
    "    # список с предобработанными данными\n",
    "    list_data_prep = []\n",
    "\n",
    "    for i in range(len(list_data_dir)):\n",
    "        if 'preprocessed_part' in list_data_dir[i]:\n",
    "            list_data_prep.append(list_data_dir[i])\n",
    "\n",
    "    # Счётчики\n",
    "    all_prep_parts = []\n",
    "#     size = 0\n",
    "\n",
    "    for i in range(len(list_data_prep)):\n",
    "        print(f'Loaded prep part {i}')\n",
    "        # Чтение\n",
    "        temp_df = pd.read_parquet(f'{LOCAL_DATA_PATH}/{PREP_DATA}/{list_data_prep[i]}')\n",
    "\n",
    "        # Уменшение памяти\n",
    "        temp_df = temp_df.astype(np.int32(0), errors='ignore')\n",
    "        \n",
    "        # массив со всеми данными для объединения\n",
    "        all_prep_parts.append(temp_df) \n",
    "    \n",
    "    del list_data_prep, temp_df, list_data_dir\n",
    "    \n",
    "    # Соединение всех частей\n",
    "    all_df = pd.concat(all_prep_parts, ignore_index = True)\n",
    "    print(f'\\nconcat {all_df.shape}\\nall_df.isna() = {all_df.isna().sum().sum()}')\n",
    "    del all_prep_parts\n",
    "    \n",
    "    # работа с пропусками и размерами данных\n",
    "    all_df = all_df.fillna(value=np.int32(0))\n",
    "    print(f'\\nfillna\\nall_df.isna() = {all_df.isna().sum().sum()}')\n",
    "\n",
    "    all_df = all_df.astype(np.int32, errors='ignore')\n",
    "    all_df[['cpe_manufacturer_name',\n",
    "            'cpe_model_os_type']] = all_df[['cpe_manufacturer_name',\n",
    "                                            'cpe_model_os_type']].astype('category')\n",
    "    print(f\"\\nastype(np.int32) + .astype('category')\")\n",
    "\n",
    "    # Запись подготовленного общего датасета в файл\n",
    "    all_df.to_parquet(f\"{LOCAL_DATA_PATH}/{PREP_DATA}/all_prep_data.parquet\")\n",
    "    print('all_prep_data was saved to file successfully')\n",
    "\n",
    "    del all_df\n",
    "    gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d55b504d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded prep part 0\n",
      "Loaded prep part 1\n",
      "Loaded prep part 2\n",
      "Loaded prep part 3\n",
      "Loaded prep part 4\n",
      "Loaded prep part 5\n",
      "Loaded prep part 6\n",
      "Loaded prep part 7\n",
      "Loaded prep part 8\n",
      "Loaded prep part 9\n",
      "\n",
      "concat (415307, 6137)\n",
      "all_df.isna() = 905735976\n",
      "\n",
      "fillna\n",
      "all_df.isna() = 0\n",
      "\n",
      "astype(np.int32) + .astype('category')\n",
      "all_prep_data was saved to file successfully\n"
     ]
    }
   ],
   "source": [
    "merge_parts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "71ca28c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Проверка на наличие пропусков в основных признаках\n",
    "# all_df[['user_id','cpe_manufacturer_name', 'cpe_model_os_type', 'price',\n",
    "#        'day', 'evening', 'morning', 'night', 'fri', 'mon', 'sat', 'sun', 'thu',\n",
    "#        'tue', 'wed']]#.isna().sum()#.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045c302d",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.2. Датасет для предсказаний по id_to_submit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6664c4eb",
   "metadata": {},
   "source": [
    "id_to_submit - id по которым нужно сделать предсказания\n",
    "\n",
    "\n",
    "df_submit - all_prep_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d9e8f380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_submit was saved to file successfully\n"
     ]
    }
   ],
   "source": [
    "# load\n",
    "id_to_submit = pd.read_parquet(f'{LOCAL_DATA_PATH_mts}/{SUBMIT_FILE}').reset_index(drop=True) \n",
    "df_submit = pd.read_parquet(f'{LOCAL_DATA_PATH}/{PREP_DATA}/all_prep_data.parquet')\n",
    "\n",
    "# merge id_to_submit и all_prep_data по \"user_id\"\n",
    "# Соединяю все полученные данные с искомыми id из сабмита для фин. пресдказаний\n",
    "df_submit = df_submit.merge(id_to_submit, how=\"inner\", on=[\"user_id\"])\n",
    "\n",
    "# save\n",
    "df_submit.to_parquet(f\"{LOCAL_DATA_PATH}/{PREP_DATA}/df_submit.parquet\")\n",
    "print('df_submit was saved to file successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b417ec",
   "metadata": {},
   "source": [
    "Сравнение количества полученных id из предобработанного датасета с количеством в заданном датасете на наличие потерь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c1cae36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_submit.shape[0] == df_submit.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "09945a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 144724 entries, 0 to 144723\n",
      "Columns: 6137 entries, user_id to znamenitosti.info\n",
      "dtypes: category(2), int32(6135)\n",
      "memory usage: 3.3 GB\n"
     ]
    }
   ],
   "source": [
    "df_submit.info()\n",
    "del df_submit, id_to_submit\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d985bc8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0ea16b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_submits():\n",
    "    \"\"\"\n",
    "    Датасет для предсказаний.\n",
    "    id_to_submit - id по которым нужно сделать предсказания\n",
    "    df_submit - all_prep_data\n",
    "    \"\"\"\n",
    "    # load\n",
    "    id_to_submit = pd.read_parquet(f'{LOCAL_DATA_PATH_mts}/{SUBMIT_FILE}').reset_index(drop=True) \n",
    "    df_submit = pd.read_parquet(f'{LOCAL_DATA_PATH}/{PREP_DATA}/all_prep_data.parquet')\n",
    "\n",
    "    # merge id_to_submit и all_prep_data по \"user_id\"\n",
    "    # Соединяю все полученные данные с искомыми id из сабмита для требуемых пресдказаний\n",
    "    df_submit = df_submit.merge(id_to_submit, how=\"inner\", on=[\"user_id\"])\n",
    "\n",
    "    # save\n",
    "    df_submit.to_parquet(f\"{LOCAL_DATA_PATH}/{PREP_DATA}/df_submit.parquet\")\n",
    "    print('df_submit was saved to file successfully')\n",
    "    \n",
    "    del id_to_submit, df_submit\n",
    "    gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2020d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_submit was saved to file successfully\n"
     ]
    }
   ],
   "source": [
    "merge_submits()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c11810b",
   "metadata": {},
   "source": [
    "## 3.3. Датасет для обучениия с целевой переменной."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8e9b19",
   "metadata": {},
   "source": [
    "# туть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba1782d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07876e78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7023bd25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_with_targets was saved to file successfully\n"
     ]
    }
   ],
   "source": [
    "# load\n",
    "all_df = pd.read_parquet(f\"{LOCAL_DATA_PATH}/{PREP_DATA}/all_prep_data.parquet\")\n",
    "targets = pd.read_parquet(f\"{LOCAL_DATA_PATH}/{PREP_DATA}/targets_age_prep.parquet\")\n",
    "\n",
    "# объединение targets и all_prep_data\n",
    "# для первичного обучения моделей\n",
    "df = all_df.merge(targets, how=\"inner\", on=[\"user_id\"])\n",
    "\n",
    "# save\n",
    "# Запись prep. данных с учителем после общего объединения\n",
    "df.to_parquet(f\"{LOCAL_DATA_PATH}/{PREP_DATA}/prep_data_with_targets_age.parquet\")\n",
    "print('df_with_targets was saved to file successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "69d4bc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 268912 entries, 0 to 268911\n",
      "Columns: 6138 entries, user_id to age_target\n",
      "dtypes: category(2), int32(6135), int8(1)\n",
      "memory usage: 6.1 GB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "del all_df, df, targets\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc3ef0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_with_targets was saved to file successfully\n"
     ]
    }
   ],
   "source": [
    "# load\n",
    "all_df = pd.read_parquet(f\"{LOCAL_DATA_PATH}/{PREP_DATA}/all_prep_data.parquet\")\n",
    "targets = pd.read_parquet(f\"{LOCAL_DATA_PATH}/{PREP_DATA}/targets_is_male_prep.parquet\")\n",
    "\n",
    "# объединение targets и all_prep_data\n",
    "# для первичного обучения моделей\n",
    "df = all_df.merge(targets, how=\"inner\", on=[\"user_id\"])\n",
    "\n",
    "# save\n",
    "# Запись prep. данных с учителем после общего объединения\n",
    "df.to_parquet(f\"{LOCAL_DATA_PATH}/{PREP_DATA}/prep_data_with_targets_is_male.parquet\")\n",
    "print('df_with_targets was saved to file successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e24312a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 263499 entries, 0 to 263498\n",
      "Columns: 6138 entries, user_id to is_male\n",
      "dtypes: category(2), int32(6135), int8(1)\n",
      "memory usage: 6.0 GB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "del all_df, df, targets\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd8922b",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. EDA parts.\n",
    "\n",
    "#### Продолжение в следующем ноутбуке =)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e8add7",
   "metadata": {},
   "source": [
    "для удобства исследования создаю общий датасет с гендером и возрастом отбросив 5413 значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6865677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_with_targets was saved to file successfully\n"
     ]
    }
   ],
   "source": [
    "# Объединение таргетов\n",
    "targets1 = pd.read_parquet(f\"{LOCAL_DATA_PATH}/{PREP_DATA}/targets_age_prep.parquet\")\n",
    "targets2 = pd.read_parquet(f\"{LOCAL_DATA_PATH}/{PREP_DATA}/targets_is_male_prep.parquet\")\n",
    "targets_df = targets1.merge(targets2, how=\"inner\", on=[\"user_id\"])\n",
    "\n",
    "# Объединение таргетов с предоббработанным датасетом\n",
    "all_df = pd.read_parquet(f\"{LOCAL_DATA_PATH}/{PREP_DATA}/all_prep_data.parquet\")\n",
    "df = all_df.merge(targets_df, how=\"inner\", on=[\"user_id\"])\n",
    "\n",
    "# Запись\n",
    "df.to_parquet(f\"{LOCAL_DATA_PATH}/{PREP_DATA}/prep_data_with_2_targets.parquet\")\n",
    "print('df_with_targets was saved to file successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6504b5fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43c53694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 263499 entries, 0 to 263498\n",
      "Columns: 6139 entries, user_id to is_male\n",
      "dtypes: category(2), int32(6135), int8(2)\n",
      "memory usage: 6.0 GB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "del targets1, targets2, targets_df, df, all_df\n",
    "gc.collect();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
